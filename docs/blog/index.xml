<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on The LambdaStack Project</title>
    <link>http://lambdastack.io/blog/index.xml</link>
    <description>Recent content in Blogs on The LambdaStack Project</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&lt;p&gt;Copyright (c) 2017, Chris Jones; all rights reserved. All comments and views are my own and not my employer&#39;s.&lt;/p&gt;&lt;p&gt;All content originating from Chris Jones is licensed under &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Attribution-ShareAlike 4.0 International&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/cjones303/&#34;&gt;Click here to contact me.&lt;/a&gt;&lt;/p&gt;</copyright>
    <lastBuildDate>Sat, 18 Mar 2017 01:00:00 +0200</lastBuildDate>
    <atom:link href="http://lambdastack.io/blog/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Hardware Sizing - Ceph Radosgw (RGW)</title>
      <link>http://lambdastack.io/blog/2017/03/18/hardware-sizing-ceph-rgw/</link>
      <pubDate>Sat, 18 Mar 2017 01:00:00 +0200</pubDate>
      
      <guid>http://lambdastack.io/blog/2017/03/18/hardware-sizing-ceph-rgw/</guid>
      <description>

&lt;h2 id=&#34;hardware-sizing-ceph-radosgw-rgw&#34;&gt;Hardware Sizing - Ceph Radosgw (RGW)&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;m often asked, &amp;ldquo;what&amp;rsquo;s the best hardware to use for Ceph?&amp;rdquo; The answer is simple - it depends. With Ceph there are many moving parts such as:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Ceph Monitor Nodes&lt;/p&gt;

&lt;p&gt;Ceph RGW Nodes&lt;/p&gt;

&lt;p&gt;Ceph Mgr Nodes&lt;/p&gt;

&lt;p&gt;Ceph OSD Nodes&lt;/p&gt;

&lt;p&gt;Ceph MDS Nodes&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In addition to those nodes you may also have software or hardware load-balancers in front of your RGW nodes. This discussion is centered around RGW nodes only. Other articles will detail out the specifics for the other nodes.&lt;/p&gt;

&lt;p&gt;RGW nodes are known as a client to RADOS, core of Ceph itself. Since it&amp;rsquo;s a client it means it&amp;rsquo;s not required unless you want an S3 or Swift Object Store interface. By default Ceph is setup to use a &amp;ldquo;private&amp;rdquo; and &amp;ldquo;public&amp;rdquo; network interface to communicate between itself. The OSD nodes utilize both interfaces with the OSD-to-OSD communication being done over the &amp;ldquo;private&amp;rdquo; network interface and &amp;ldquo;client&amp;rdquo; interfacing being done over the &amp;ldquo;public&amp;rdquo; interface. This means that all &amp;ldquo;clients&amp;rdquo; (like RGW) only use the &amp;ldquo;public&amp;rdquo; interface and not the &amp;ldquo;private&amp;rdquo; interface.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You have the option on OSD nodes to use separate network interfaces for &amp;ldquo;public&amp;rdquo; and &amp;ldquo;private&amp;rdquo; or a single larger aggregate network interface where you run both types of traffic over a single interface. Your option.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;After running RGW nodes on small and large clusters in both dedicated (storage only) and Hyper-Converged with OpenStack and Ceph on the same nodes, I have seen that RGW itself (on a per instance basis) is more of a limitation than the hardware. For example, I had one configuration with 256GB RAM with two 10Gbps NICs bonded in mode 4 (aggregate) and running multiple RGW instances answering on different ports. After tracking the throughput of the network bond (bonds are not my preferred way but that&amp;rsquo;s what I had) and increasing Civetweb threads along with RGW thread pools and rados handles, I found that my bottle neck was RGW and not the hardware. Using CollectD metrics I found that the CPUs (24) ran mostly around 94% idle, memory percent used was not high and network traffic would top at around 6-8Gbps sustained (full duplex). I would also see thread counts as high 32K per instance. For the record, no logging on RGW and I started with a single RGW instance and ended up with four instances on different ports.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m still testing different configurations but when it comes to sizing RGW nodes, the following is a good guideline:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;1U size&lt;/p&gt;

&lt;p&gt;1 10Gb NIC (minimum) for small-medium traffic and cluster size - Jumbo frames&lt;/p&gt;

&lt;p&gt;1 20Gb NIC (minimum) for larger cluster size and higher traffic - Jumbo frames&lt;/p&gt;

&lt;p&gt;64-128GB RAM will be more than enough for most clusters&lt;/p&gt;

&lt;p&gt;Dual OS small SSDs in RAID 1&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the configuration that I mentioned earlier, you can even run extra Ceph Monitor processes on those same nodes and still have plenty of idle capacity.&lt;/p&gt;

&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;

&lt;p&gt;Ceph RGW itself is the real bottle neck on throughput and not the hardware you choose. There is a sweet spot of finding the right mix of civetweb threads, RGW thread pool and other settings which require a lot of trial and error with your hardware and network configuration. You can run multiple instances of RGW using different ports (just have to have a section in the ceph.conf for each instance name along with the corresponding keyring - take a look at &lt;a href=&#34;https://github.com/bloomberg/chef-bcs&#34;&gt;https://github.com/bloomberg/chef-bcs&lt;/a&gt; for how to setup and run large clusters) but you need a good load-balancer in front of them (HAProxy or commercial).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AWS S3 vs On-Premises</title>
      <link>http://lambdastack.io/blog/2017/03/09/aws-vs-onprem/</link>
      <pubDate>Thu, 09 Mar 2017 20:00:00 +0200</pubDate>
      
      <guid>http://lambdastack.io/blog/2017/03/09/aws-vs-onprem/</guid>
      <description>

&lt;h2 id=&#34;aws-s3-vs-on-premises&#34;&gt;AWS S3 vs On-Premises&lt;/h2&gt;

&lt;p&gt;When you own Enterprise Storage or are asked to build enterprise class storage you find yourself more frequently having to cost justify against outside Cloud Storage vendors like AWS S3, GCE or Azure. So, how will you do that since you have to make capital expenditures vs OpEx that these providers discuss so much?&lt;/p&gt;

&lt;p&gt;When you break down the pricing of AWS S3 and others you find that the actual storage cost is not too bad (depending on amount of stored data). What you don&amp;rsquo;t realize is the network transfer rate is where they get you. I have heard stories of small firms having bet pools going just to see who is closer at guessing a given days AWS cost. The same can be said for enterprises but the stakes are much higher!&lt;/p&gt;

&lt;h4 id=&#34;sidebar&#34;&gt;Sidebar&lt;/h4&gt;

&lt;p&gt;I like AWS, Azure and Google. They serve a good purpose of helping you get started on projects at a low entry cost and the &amp;ldquo;pay-as-you-go&amp;rdquo; model is very compelling. This model changes over time for some enterprises especially when it comes to storage. I just recently had a Senior level &amp;ldquo;Amazonian&amp;rdquo; (that&amp;rsquo;s what they call themselves) say &amp;ldquo;AWS is the world largest startup and that&amp;rsquo;s how we operate.&amp;rdquo; That sounds kinda cool but when I pressed him on enterprise like questions, his story fell flat. AWS seems to believe everything should run in a public cloud but that&amp;rsquo;s just not wise (in a general sense - some enterprises can&amp;rsquo;t allow their data outside their datacenters for many reasons).  Azure actually understands this and has &amp;ldquo;on-premises&amp;rdquo; versions of some of their offerings. They seem to have more of an understanding of the enterprise than the others.&lt;/p&gt;

&lt;p&gt;Again, I like AWS. I wrote the Rust AWS-SDK-RUST SDK and other S3 tools. I&amp;rsquo;m simply making honest comparisons of cloud providers for enterprises. I have also used Google on past contracts and they are very good but I don&amp;rsquo;t have an enterprise reference to compare against.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Also, don&amp;rsquo;t get confused by AWS&amp;rsquo; &amp;ldquo;manage your on-premises via AWS.&amp;rdquo; It&amp;rsquo;s only their console that you can plug some data into and not a true on-premises solution.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;how-to-cost-justify&#34;&gt;How to cost justify&lt;/h4&gt;

&lt;p&gt;Back from my sidebar. How do we cost justify on-premises S3 and compare it to AWS S3? The first thing is &lt;strong&gt;DO NOT&lt;/strong&gt; use a tradition enterprise storage vendor - you gain nothing. You need a solid open source solution using COTS (Common Off The Shelf) hardware such as Ceph on any hardware platform that meets your budget and minimum requirements to run a good S3 Object Store.&lt;/p&gt;

&lt;p&gt;Cost Example (deep storage): (NB: These are conservative costs. You will need to plug in your costs. This also assumes you use all of the storage and most of data is machine generated as in Big Data. Also, no operating labor cost is factored in since that is so variable [see summary].)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Single datacenter. Data is very durable with Erasure Coding.&lt;/p&gt;

&lt;p&gt;5 Racks ($300K each) - $1,500,000 (assumes your own datacenters with power/cooling - cost factors in ~10 spare storage nodes and additional 10TB HDD for replacements). Also these figures are high so your real figures should be a good bit less depending on your hardware vendor and even lower if you don&amp;rsquo;t have to use outside vendors and contractors.&lt;/p&gt;

&lt;p&gt;Includes racks, high-density storage, network spines, 20Gbs NICs, TORs, software load-balancers (HAProxy), install labor, spares, etc&lt;/p&gt;

&lt;p&gt;Ceph S3, Erasure Coding &lt;sup&gt;8&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; (11 shards - &lt;a href=&#34;http://lambdastack.io/blog/2017/02/26/erasure-coding/&#34;&gt;see other article on EC calculations&lt;/a&gt;) - tuned for larger objects&lt;/p&gt;

&lt;p&gt;10TB HDD x 204 (drives per rack) x 5 (racks) = 10.2PB raw storage / 1.375 (EC factor - see EC article) = 7,418TB (7.4PB) usable. Using EC instead of replica for better storage utilization. ~3% write overhead and ~1.2% read overhead for EC as compared to replicas. The big penalty will come on a rebuild of an object if required due to data failure etc.&lt;/p&gt;

&lt;p&gt;$1,500,000 (total cost) / 7,418TB (usable) = $202.21 per TB (internally price this one-time, annually or however you like. This example will be one-time (1 year) divided into monthly)&lt;/p&gt;

&lt;p&gt;Operational costs (power/cooling/space density) are standardize (PUE). A normal rack uses less than ~5kW on average and I will use $.10 kW/h cost (change to your areas average): 8,760 (annual hours) * $.10 * 5 = $4,104.06 * 5 (racks) = $20,520.30 (annual) / 7,418TB (usable) = $2.77TB for OpEx (annual)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;$202.21 + $2.77 = $204.98TB (first year). $2.77TB annual after first year plus operational labor&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;NB: If you use commercial hardware load-balancers then your cost will increase. These do not usually gain you performance over HAProxy in this scenario. However, you can always add them and repurpose the HAProxy nodes included above.&lt;/p&gt;

&lt;p&gt;Network traffic - ~20Gbs (.0025TBps) sustained (give or take) split with &lt;sup&gt;70&lt;/sup&gt;&amp;frasl;&lt;sub&gt;30&lt;/sub&gt; read/write (change based on your assumptions but these values are used for standard benchmarking). Since a high-speed network is part of a normal enterprise (large), there are no additional costs for network usage in this scenario beyond purchasing additional spines which are factored into the cost. (Internal only)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;AWS S3 (published pricing):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Store 7,418TB to be equal with above&lt;/p&gt;

&lt;p&gt;Replication with datacenter (standard). Replication to other regions will cost more.&lt;/p&gt;

&lt;p&gt;Transfer In &lt;a href=&#34;https://aws.amazon.com/snowmobile/&#34;&gt;(Would take a &amp;ldquo;snowmobile&amp;rdquo; - Big semi-tractor and trailer rigs)&lt;/a&gt;. This scenario doesn&amp;rsquo;t even cover that cost but it&amp;rsquo;s expensive and takes a long time.&lt;/p&gt;

&lt;p&gt;Transfer Out - 70TB monthly (this is only a fraction [2.33TB] per day of the on-premises example above) - Transfer out applies to everything including EC2, Direct Connect etc.&lt;/p&gt;

&lt;p&gt;Direct Connect - Would need 2 LAG 10Gbs circuits plus additional equipment to sustain internal rate above. The cost is not reported here and much higher (setup, monthly and long-term contract)!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;$176,110.98 (monthly) * 12 = $2,113,331.76 (annual) / 7,418TB = $284.89TB (annual) PLUS costs not reported!!&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;http://lambdastack.io/img/aws-s3-worksheet.png&#34; style=&#34;max-width: 100%&#34;&gt;
&lt;strong&gt;AWS online worksheet - &lt;a href=&#34;https://calculator.s3.amazonaws.com/index.html&#34;&gt;https://calculator.s3.amazonaws.com/index.html&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://lambdastack.io/img/aws-s3-detail.png&#34; style=&#34;max-width: 100%&#34;&gt;
&lt;strong&gt;AWS detail&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;summary&#34;&gt;Summary&lt;/h4&gt;

&lt;p&gt;If you are a startup and only using a small amount of storage then you can easily cost justify using a public cloud provider. However, if you are an enterprise and own datacenters then it&amp;rsquo;s far better from a cost stand point to build your own S3 on-premises and maintain control (even with added operational labor costs). The above scenario takes into consideration only one datacenter for the on-premises so the cost look very good for it even starting in the first year. However, if you factor in a second datacenter, just double the cost to keep it easy, then you see that year one (only) is better (from a cash outlay) for AWS S3 (w/o high transfer rate and Direct Connect costs).&lt;/p&gt;

&lt;p&gt;Second datacenter factored in for on-premises:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;$3,000,000 for 2 datacenters with ~10 spare servers and drives per datacenter.&lt;/p&gt;

&lt;p&gt;$204.98TB x 2 = $409.96TB (annual) or $409.96TB / 3 (3 years) = $136.65TB annually over 3 year period.&lt;/p&gt;

&lt;p&gt;Factor in replication costs of AWS S3 to other regions if comparing with multiple datacenters of on-premises.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;p&gt;GCE (Update):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Taken from Google Cloud Platform calculator website showing difference in GCE and AWS for 10PB single region (single site). Notice how high both are with AWS being the highest.
&lt;img src=&#34;http://lambdastack.io/img/gce.png&#34; style=&#34;max-width: 100%&#34;&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;p&gt;Using the above cost figures, the AWS S3 cost will remain annual while the on-premises&amp;rsquo; cost go down annually due to many factors but mainly due to shelf life of 3-5yrs of equipment. Of course, there will be the annual OpEx costs mentioned plus drive and server replacement costs (some were already factored into the initial cost). The on-premises version also does not include operational labor costs (important). However, the labor cost would most likely only get you closer on year one using the single datacenter scenario.&lt;/p&gt;

&lt;p&gt;The point is, there are many ways to approach the cost points. If you have a lot of data and it continues to grow at an exponential rate and you continue to find more ways to process (analyze) the data then your transfer out of storage rates will increase (same transfer costs apply to EC2 and Direct Connect) and thus your real cost of AWS S3. This can also be applied to AWS Glacier as well.&lt;/p&gt;

&lt;p&gt;Again, AWS S3 is great but it is more expensive than you think when you have a lot of data and need access to it frequently. But if you&amp;rsquo;re a small shop or just want someone else to manage things for you, it&amp;rsquo;s a good option. Just don&amp;rsquo;t assume it&amp;rsquo;s cheaper because it&amp;rsquo;s not especially when you get into PB range which is now becoming a norm.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;Tested S3 from EC2 large in us-east-1 (same) region using JMeter and used same EC2 JMeter tests against Ceph in DMZ (owned datacenter - not close to region) and Ceph won in performance in most tests. Was not testing for performances between the two but was testing to establish a base line. Results were very surprising! Take away - do a lot of tests because results can be counter intuitive.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hyper-Converged Infrastructure (HCI) - Truth</title>
      <link>http://lambdastack.io/blog/2017/03/05/hci/</link>
      <pubDate>Sun, 05 Mar 2017 01:00:00 +0200</pubDate>
      
      <guid>http://lambdastack.io/blog/2017/03/05/hci/</guid>
      <description>

&lt;h2 id=&#34;hyper-converged-infrastructure-hci-truth&#34;&gt;Hyper-Converged Infrastructure (HCI) - Truth&lt;/h2&gt;

&lt;p&gt;I happened to just stumble upon a few marketing oriented whitepapers from VMWare today (odd use of my time). All three were centered around Hyper-Converged Infrastructure (HCI). At Bloomberg, we run VMWare and OpenStack clusters. Our OpenStack clusters are currently fully Hyper-Converged. I have even given talks on them &lt;a href=&#34;http://lambdastack.io/videos/openstack-austin/&#34;&gt;http://lambdastack.io/videos/openstack-austin/&lt;/a&gt;. If you look at the video and the presentation you will see why we no longer believe in this model for us.&lt;/p&gt;

&lt;p&gt;We have many clusters and some are very large. Our compute and storage run on the same nodes in these clusters. We even went to a &amp;ldquo;POD&amp;rdquo; like system (three PODs per rack) to help us scale as seen in the presentation. When we first started out over four years ago, Hyper-Converged was not the buzzword it is today and it made sense at the time. However, today, it&amp;rsquo;s a different story.&lt;/p&gt;

&lt;p&gt;VMWare is seemingly pushing HCI as the greatest thing since sliced bread. They have even produced a whitepaper on how to better your career by embracing it. We have found that HCI only works for small clusters will a limited work load. Scaling an HCI is very complicated and costly. The storage portion is the part that really needs the most scale so scaling compute to fit the scale needs of storage can be a waste of resources.&lt;/p&gt;

&lt;p&gt;If you charge your internal customers for compute resources and storage resources then an HCI can cause their cost to be very high even with oversubscription of compute. Last year we began the process of breaking out compute from storage so that we could scale them independently of each other.&lt;/p&gt;

&lt;p&gt;After we began to split out our storage, we were able to pass along a dramatic drop in per TB charge to our internal customers which was not possible before. Storage and compute resource needs are different. We suspected we would see a drop in issues due to the reduced pressure on resources which we did. However, we were surprised at how much more healthy our nodes became due to this.&lt;/p&gt;

&lt;p&gt;Vendors like to create buzzwords but I often wonder if they really actually eat their own dog food so to speak and operate things at massive scale or if everything is simply based on theory. I suspect the latter. In our experience, Hyper-Converged can work good enough at a small scale but it does not do well at scale. Vendors that are pushing it are just trying to survive in a changing world. Make sure it&amp;rsquo;s right for you before investing.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CI/CD Risk</title>
      <link>http://lambdastack.io/blog/2017/02/28/risk/</link>
      <pubDate>Tue, 28 Feb 2017 01:30:27 -0400</pubDate>
      
      <guid>http://lambdastack.io/blog/2017/02/28/risk/</guid>
      <description>

&lt;h3 id=&#34;ci-cd-risk&#34;&gt;CI/CD Risk&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Portions of this content are from Randy Bias @ cloudscaling.com under creative commons&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In the DevOps mythos or worldview, continuous delivery (“CD”) is considered one of the holy mantras. Unfortunately, many take CD to an extreme that is unwarranted and not even reflected in how the DevOps originators (e.g. Amazon, Google) operate. This is one of those situations where folks are extrapolating and providing an interpretation of DevOps that isn’t really accurate. The foundational problem is that all code update and delivery problems are treated equally, when they really aren’t equal. The reality of continuous integration (CI) and continuous delivery (CD) or “CI/CD” is that code deployment risk varies by application. Variance in risk means that there must be variance in testing and frequency of code deployments.&lt;/p&gt;

&lt;p&gt;One reason this is true, for example, is that the CI/CD story of success requires several key items. First, that code changes are relatively small, reducing risk. Second, that code changes are frequent. Third, that one side effect of small and frequent is that issues can be fixed with a “roll forward” instead of a “roll back.” Meaning that if a mistake is made or a bug introduced, you simply turn the crank one more time and release an update. Or, for those of you who watched John Allspaw’s presentations on Flickr “Dev and Ops” methodologies in the early days of Velocity Conference (DevOps before the term was coined!), the ability to turn off troublesome features (“feature flags”) in real time (as opposed to a roll forward).&lt;/p&gt;

&lt;p&gt;But what happens when your code deployment breaks everything and a roll forward is no longer possible? This issue is, unfortunately, glossed over by many. And that’s because much of the original thinking of a rapid CI/CD release pipeline was focused around websites and the application layer. It has largely ignored the infrastructure layer. Infrastructure is more sensitive to a catastrophic change because if the infrastructure fails, everything fails. In effect, the “blast radius” of infrastructure failures is significantly larger than that of application failures.&lt;/p&gt;

&lt;p&gt;Lately I’m seeing more and more magical thinking that CI/CD can be applied equally to the infrastructure layer and it simply can’t. Let’s dig in further.&lt;/p&gt;

&lt;h4 id=&#34;background&#34;&gt;Background&lt;/h4&gt;

&lt;p&gt;In the early days of “DevOps”, before the term was really coined, the hotbed of activity was around small meet ups and the Velocity Conference. I remember at one of the early Velocity Conferences (probably 2008 or 2009) hanging out with many of the early folks in this space. We were fortunate to have some of the Amazon team there who shared in confidence about Amazon.com’s ATLAS system that was used to do “thousands of deployments per day.” These were the first glimpses into the pioneering tool work the web scale folks had done around “DevOps”. As most of you know, DevOps origins were about breaking down the “responsibility barrier” between developer and operators, which simultaneously required a re-think of the tools used to manage and deliver site updates.&lt;/p&gt;

&lt;p&gt;Amazon’s ATLAS system put the deploy button in the hands of the developers. Pre-AWS services had been deployed inside of Amazon that allowed for developers to “order up” compute, storage, networking, messaging, and the like. Much of this work is what inspired Amazon Web Services (AWS) and also the tooling work developed around “DevOps” and rapid CI/CD release pipelines.&lt;/p&gt;

&lt;p&gt;However, most of this work was done at the application layer and some of it at the platform layer. Very little of a rapid release was performed around the infrastructure layer itself.&lt;/p&gt;

&lt;p&gt;Somehow, this work and the general sentiments of the DevOps community have erroneously performed a straight line extrapolation of how these techniques should be applied to the infrastructure layer. I see members of communities push for rapid release cycles of infrastructure code. Usually these folks have little history with running large infrastructure systems.&lt;/p&gt;

&lt;p&gt;When we look at large-scale infrastructure, the story (even for the web scale folks) is one of stability and consistency, not constant change. There is simply a different risk profile for infrastructure. For example, AWS is notorious for running forked versions of Xen 3.x after they were deprecated. In fact, AWS rarely, if ever updates the Xen hypervisor due to the inherent risk.&lt;/p&gt;

&lt;h4 id=&#34;differing-risk-profiles&#34;&gt;Differing Risk Profiles&lt;/h4&gt;

&lt;p&gt;A web application and infrastructure systems have different risk profiles. If your application has a bug introduced that causes it to fail completely during an arbitrary update, you still have the ability to talk to the infrastructure. That means you can “roll forward” or reload your application onto the infrastructure from scratch in a worst case scenario. All of this is usually fully automated.&lt;/p&gt;

&lt;p&gt;On the other hand, a failure of the core infrastructure, like storage or networking, could cause a catastrophic failure that would preclude reloading the system trivially. Yes, you could wipe the bare metal and reset if you have access to the metal, but you are talking about a significant amount of time to reset. Or, say for example, that you were using a software virtualization technique such as software-defined-networking (SDN) or software-defined-storage (SDS) for networking and storage. What happens if you bring your SDN system down hard and can no longer reach the control plane? Or if you introduce a software bug to your SDS that actively damages your datasets causing you to have to reload from backups or resynchronize from a secondary system - as in the case of distributed storage systems like Ceph.&lt;/p&gt;

&lt;p&gt;Infrastructure simply has a different risk profile and requires you to be more careful, to do more active up front testing, and to be more certain about code updates.&lt;/p&gt;

&lt;h4 id=&#34;cloud-dependency-model&#34;&gt;Cloud Dependency Model&lt;/h4&gt;

&lt;p&gt;The following diagram highlights these differences.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://lambdastack.io/img/cicd/cloud-dependency-model.jpeg&#34; style=&#34;max-width: 100%&#34;&gt;&lt;/p&gt;

&lt;p&gt;You have probably seen the traditional cloud pyramid at some point. When considering differences in risk it is best to understand dependency. All applications and services depend on infrastructure at some layer, whereas infrastructure (compute, storage, and network) have no dependency whatsoever on the apps that run on top of them. Catastrophic failures at lower levels will impact apps running above, usually many apps.&lt;/p&gt;

&lt;p&gt;It’s also important to understand that part of what the web-scale cloud computing pioneers like Google and Amazon taught us is that infrastructure should be relatively homogeneous (“homologous”). Google can manage 10,000 physical servers with a single admin because they only have a handful of configurations. This persists across all cloud infrastructure. Typically the cost per unit, the variability of the configurations, and the cost to operate are all low.&lt;/p&gt;

&lt;p&gt;Applications and services however are more costly to operate, the cost to develop them is higher as by definition they are bespoke, being written from scratch to drive critical business functions, and variability between different kinds of applications is high.&lt;/p&gt;

&lt;p&gt;In other words, apps are only dependent on other apps, are closer to customers, are bespoke and highly heterogeneous, requiring regular rapid releases and roll-forward methodologies.&lt;/p&gt;

&lt;p&gt;So when we think about these things we need to realize that because platforms and apps are dependent on infrastructure a high rate of change creates more risk. We do want to be able to update infrastructure faster than in the past, but hourly, daily, and even weekly changes introduce the possibility of catastrophic failures. More vetting is inherently required.&lt;/p&gt;

&lt;h4 id=&#34;the-need-for-speed&#34;&gt;The Need for Speed&lt;/h4&gt;

&lt;p&gt;I get it. You want to go fast. Really fast. That means you want to update your infrastructure layer features more frequently. Frankly, you should be able to. This is a new age and the need for speed is an imperative for us all. If you are a carrier, telco, or cable operator you feel the need, in particular, to get rapid updates to your network infrastructure. You’re right, you shouldn’t have to wait to update your network once a year or once every two years. But asking to update your network every hour, every day, or every week is a recipe for significant downtime.&lt;/p&gt;

&lt;p&gt;There is a sweet spot. Quarterly updates for major feature changes and monthly updates for security fixes will increase your overall velocity, while keeping risk to a tolerable minimum. Any faster and you’ll be bleeding customers.&lt;/p&gt;

&lt;h4 id=&#34;a-busted-myth&#34;&gt;A Busted Myth&lt;/h4&gt;

&lt;p&gt;It is sad to see the story of the rapid DevOps CI/CD pipeline extrapolated unnecessarily to the infrastructure layer. Companies, pundits, and DevOps leaders are possibly creating a climate that leads to greater downtime by taking this approach. It is not proven in production anywhere. Large scale infrastructure businesses with high uptime like Google and Amazon simply aren’t doing this and for good reason: the risk profile for infrastructure is different than the applications that run on top of that infrastructure.&lt;/p&gt;

&lt;p&gt;They do however develop CI pipelines and secondary non-production systems that take regular infrastructure code updates so that they can do extensive testing before rolling out infrastructure code updates. It’s not uncommon for large infrastructure code updates to be tested for many months before being rolled out. The risk is simply too high that if something goes wrong there will be significant down time or data loss.&lt;/p&gt;

&lt;p&gt;Calibrate your DevOps thinking to bring risk to the equation. CI/CD without risk assessment is foolhardy.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You can see Randy&amp;rsquo;s complete post at &lt;a href=&#34;http://cloudscaling.com/blog/&#34;&gt;http://cloudscaling.com/blog/&lt;/a&gt;. Randy talks about how testing is done for Open Contrail in that post.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;All content licensed under the &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/3.0/us/&#34;&gt;Creative Commons Attribution-Share Alike 3.0 United States&lt;/a&gt; License (CC BY-SA 3.0 US).&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SLA - Availability or Durability</title>
      <link>http://lambdastack.io/blog/2017/02/27/sla/</link>
      <pubDate>Mon, 27 Feb 2017 01:00:00 +0200</pubDate>
      
      <guid>http://lambdastack.io/blog/2017/02/27/sla/</guid>
      <description>

&lt;h3 id=&#34;sla-availability-or-durability&#34;&gt;SLA - Availability or Durability&lt;/h3&gt;

&lt;p&gt;I seem to be getting more questions lately like, &amp;ldquo;how many 9s is your object store?&amp;rdquo; or &amp;ldquo;how do you calculate 9s?&amp;rdquo;. The questions need to be narrowed down since those are very broad. For example, when dealing with storage like an object store, there are two types of &amp;ldquo;9s&amp;rdquo;. One for durability and one for availability. If you look at AWS S3, they put on their primary site 11 9s of durability which is very good. Deeper into site or FAQ you also find where they claim 4 9s of availability. Why such a difference and what does it mean?&lt;/p&gt;

&lt;h4 id=&#34;sla&#34;&gt;SLA&lt;/h4&gt;

&lt;p&gt;The SLA (Service Level Agreement) is a promise/contract from the issuer to the customer that guarantees &amp;ldquo;X level&amp;rdquo; of service. You need to really dig into the SLA to make sure that you fully understand the SLA&amp;rsquo;s definition of time. For example, without hesitation when you see a guarantee that says 11 9s or 4 9s you immediately think that everything will be available almost 100% of the time. This is usually not the case.&lt;/p&gt;

&lt;p&gt;First, make sure you understand that when you see 11 9s it usually means something like durability and not availability (but it could). A smaller number of 9s is usually reflective of availability. The reason for this can be many; networking, system failure, power and even the nature of certain protocols.&lt;/p&gt;

&lt;p&gt;The SLA itself may also define its availability time as 6 days a week instead of 7 or 20 hours a day instead of 24 which would mean the number of 9s would be higher and still allow for good bit of downtime.&lt;/p&gt;

&lt;h4 id=&#34;calculations&#34;&gt;Calculations&lt;/h4&gt;

&lt;p&gt;Availability:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;4 nines –&amp;gt; (365×24) – .9999(365×24) = 8760 – 8759.124 = 0.876 hours = 52 minutes and 30 secs&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;OR - 20 hours per day for 6 days a week&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;4 nines –&amp;gt; (365-52)x20 – .9999((365-52)x20) = 6260 – 6259.374 = 37 minutes and 30 secs&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In both examples there are 4 9s but the second one the SLA defines its time differently.&lt;/p&gt;

&lt;p&gt;Bonus:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;3 nines –&amp;gt; (365×24) – .999(365×24) = 8760 - 8751.24 = 8.76 hours = 8 hours and 45 minutes&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;NB: Google Cloud Platform and Azure also have the same level of availability as AWS S3 - 99.99%&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;durability&#34;&gt;Durability&lt;/h4&gt;

&lt;p&gt;When you see something like 11 9s of durability, it&amp;rsquo;s usually calculated using a probability theory based on many factors such as replicas, distribution of objects in a cluster, multi-site replication, type of media etc. In AWS S3 they claim 11 9s and state the following in their &lt;a href=&#34;https://aws.amazon.com/s3/faqs/#How_durable_is_Amazon_S3&#34;&gt;FAQ&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Q: How durable is Amazon S3?&lt;/p&gt;

&lt;p&gt;Amazon S3 Standard and Standard - IA are designed to provide 99.999999999% durability of objects over a given year. This durability level corresponds to an average annual expected loss of 0.000000001% of objects. For example, if you store 10,000 objects with Amazon S3, you can on average expect to incur a loss of a single object once every 10,000,000 years. In addition, Amazon S3 is designed to sustain the concurrent loss of data in two facilities.&lt;/p&gt;

&lt;p&gt;As with any environments, the best practice is to have a backup and to put in place safeguards against malicious or accidental users errors. For S3 data, that best practice includes secure access permissions, Cross-Region Replication, versioning and a functioning, regularly tested backup.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I often hear some of my data science buddies get a little testy when I say, &amp;ldquo;durability determination is more of an art than science.&amp;rdquo; What I mean by this is yes we use historical data and probability but we sometimes throw in a little juju &lt;i class=&#34;fa fa-smile-o&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;. Read the durability claims in the SLA carefully.&lt;/p&gt;

&lt;h4 id=&#34;summary&#34;&gt;Summary&lt;/h4&gt;

&lt;p&gt;Double check the SLA! In some SLAs I have seen where they never mention 9s but instead mention throughput as defined in any given 15 minute period. This of course is very vague and allows the SLA issuer to claim almost anything. This is common for internal teams in the Enterprise. Again, double check and get the issuer to explain it detail before agreeing to it.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You can also simply cheat and look at: &lt;a href=&#34;https://en.wikipedia.org/wiki/High_availability#Percentage_calculation&#34;&gt;https://en.wikipedia.org/wiki/High_availability#Percentage_calculation&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Erasure Coding vs Replica</title>
      <link>http://lambdastack.io/blog/2017/02/26/erasure-coding/</link>
      <pubDate>Sun, 26 Feb 2017 11:27:27 -0400</pubDate>
      
      <guid>http://lambdastack.io/blog/2017/02/26/erasure-coding/</guid>
      <description>

&lt;h4 id=&#34;erasure-coding-vs-replica&#34;&gt;Erasure Coding vs Replica&lt;/h4&gt;

&lt;p&gt;Ceph RadosGW (RGW), Ceph&amp;rsquo;s S3 Object Store, supports both Replica and Erasure Coding. Most all examples of using RGW show replicas because that&amp;rsquo;s the easiest to setup, manage and get your head around. Replicas simply means that a default of 3 means that RGW stores the original plus two more copies spread out within the cluster based on the Crush Map, Ceph&amp;rsquo;s way of calculating where to store objects.&lt;/p&gt;

&lt;p&gt;Erasure coding is a form of durability calculations that allows you to maintain the same or better durability as replicas but at a much better density model. Meaning, if I have three full racks of storage using the default replicas and I have set the crush map up to keep each replica on a different rack then I really only have one full rack of actual storage since the other two are used for durability. With an erasure code of &lt;code&gt;8/3&lt;/code&gt; I will have approximately 1.5 racks of actual storage which is much better. However, erasure coding comes with a cost.&lt;/p&gt;

&lt;p&gt;In the scenario of &lt;code&gt;8/3&lt;/code&gt; previously mentioned, it means that I have 8 data chunks plus 3 parity chunks for a total of 11 chunks. These chunks are then spread out over the cluster using a different crush map rule that basically says &amp;lsquo;put each object on a different node and spread them between different racks and nodes as evenly as possible&amp;rsquo;. This means that you can lose 3 objects before you would lose any data. Which also means it takes at least 8 objects to form the complete object. Different size clusters and different durability factors will dictate what &lt;code&gt;k/m (data/parity)&lt;/code&gt; value your decide on for you cluster.&lt;/p&gt;

&lt;p&gt;Earlier, I mentioned that erasure coding comes at a cost. The cost is taxed on each GET (read) and PUT (write). It takes time to calculate the parity on the PUT and time to assemble the objects on the GET. Since RGW is a guarantee &lt;code&gt;read-after-write&lt;/code&gt;, the response for a PUT does not come back until the original object&amp;rsquo;s parity is calculated, split and placed on different nodes (depending on crush map rules). The GET assembles the objects back together and then responds.&lt;/p&gt;

&lt;p&gt;Based on my tests with my multi-petabyte clusters, I have calculated approximately a little less than 20% on 2MB PUTs as compared with the same object using replicas (mileage will vary based on drive types, CPU, network, etc). The GETs were not as bad. So, if you need every ounce of performance you can get then use replicas. If you want to put as much data into the same raw density then use erasure coding. You can also test different size &lt;code&gt;k/m&lt;/code&gt; values to gauge the overall impact on your cluster (you will have to wipe the data if you change the &lt;code&gt;k/m&lt;/code&gt; values).&lt;/p&gt;

&lt;p&gt;I have been asked so often about calculating data/parity combinations that I have put together a free erasure coding k/m value calculator in Excel. I have included it in the &lt;code&gt;chef-bcs&lt;/code&gt; Chef repo at &lt;a href=&#34;https://github.com/bloomberg/chef-bcs/tree/master/cookbooks/chef-bcs/files/default/utilities&#34;&gt;https://github.com/bloomberg/chef-bcs/tree/master/cookbooks/chef-bcs/files/default/utilities&lt;/a&gt;. You can download just the spreadsheet and play with the numbers or fork the repo and automatically build Ceph clusters. Enjoy!&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/bloomberg/chef-bcs/tree/master/cookbooks/chef-bcs/files/default/utilities&#34;&gt;&lt;img src=&#34;http://lambdastack.io/img/erasure-coding.png&#34; style=&#34;max-width: 100%&#34;&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Which open source software license should I use?</title>
      <link>http://lambdastack.io/blog/2017/02/23/opensource-license/</link>
      <pubDate>Thu, 23 Feb 2017 06:00:00 +0200</pubDate>
      
      <guid>http://lambdastack.io/blog/2017/02/23/opensource-license/</guid>
      <description>&lt;p&gt;&lt;em&gt;NB: This article is from Opensource.com. I also use Apache 2 for my projects.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I’ve recently been involved in several discussions that are variations on, &amp;ldquo;Which open source or free software license should I choose for my project?&amp;rdquo; Here is my way of looking at the large and growing collection of licenses in the wild. First, let&amp;rsquo;s make sure we all understand that I Am Not A Lawyer. This is not legal advice. Depending upon your needs and your comfort with risk around your software, you&amp;rsquo;ll want to confirm your legal choices with counsel in your jurisdiction.&lt;/p&gt;

&lt;p&gt;The first and obvious consideration is whether or not the license is approved as an open source license by the Open Source Initiative (OSI). The OSI created the Open Source Definition in the late 1990s as a set of attributes that a software license must support to be considered &amp;ldquo;open source.&amp;rdquo; Anyone can take a license to the OSI for debate and discussion and if approved as meeting the OSD, then the license is added to the canonical list.&lt;/p&gt;

&lt;p&gt;While this seems an obvious place to start, I was recently surprised to discover a license called the &amp;ldquo;Clear BSD License.&amp;rdquo; It attempts to clarify explicitly that patents are not being discussed in the license. It is not on the OSI list (while the New BSD and Simplified BSD licenses are) and is therefore not worth considering. Inventing new licenses as small derivatives of existing licenses is not helpful and creates costly legal busy work. There exists a broad collection of OSI-approved licenses today. These licenses cover millions of lines of software involved in billions of dollars in procurement. One would be hard pressed to describe a serious set of circumstances that isn’t already covered by an OSI-approved license.&lt;/p&gt;

&lt;p&gt;There are several big levers available when considering an open source license:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;How much license reciprocity is required with respect to the software, modifications, and any derivatives someone develops?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What is said about patent licensing and litigation?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What legal jurisdiction covers the license?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The reciprocity issue is all about &lt;a href=&#34;http://www.gnu.org/copyleft/&#34;&gt;&amp;ldquo;copyleft&amp;rdquo;&lt;/a&gt; and whether or not using the software source code attaches the license to the modifications and derivatives, and whether the source code to those modifications and derivatives needs to be published.&lt;/p&gt;

&lt;p&gt;On one end of the spectrum are licenses that have no copyleft requirements. These licenses essentially allow anyone to use the software in anyway without requiring much more than maintaining copyrights. Licenses that fall into this set include the New and Simplified BSD licenses, the MIT license, and the Apache 2.0 and Microsoft Permissive licenses.&lt;/p&gt;

&lt;p&gt;There are a set of licenses that maintain a sense of copyleft around the software itself but support the use of the software in larger works of software which may contain software that is licensed differently (e.g. closed and proprietary). These licenses include the Eclipse Public License, the newer Mozilla Public License 2.0, and the Microsoft Reciprocal License.&lt;/p&gt;

&lt;p&gt;On the other end of the copyleft spectrum are strong copyleft licenses. &lt;a href=&#34;http://www.gnu.org/philosophy/free-sw.html&#34;&gt;Software freedom&lt;/a&gt; is defined by the Free Software Foundation in terms of the freedoms a user of software must have. Strong copyleft supports software freedom. Many developers support software freedom, and demonstrate this support using one of the family of GPL licenses (GPL2.0, GPL3.0, and the Affero GPL3.0) as a way to ensure the strongest copyleft and strongest license attachment when the software in question is used in building and distributing other software.&lt;/p&gt;

&lt;p&gt;Software patents weren’t really an issue when software was beginning to be widely shared on the early Internet and so weren’t mentioned in the early licenses. By the late 1990s, software patents were on the rise and corporate legal teams were becoming more involved in the writing of open source licenses as they became more involved with open source software and developing the open source foundations around evolving projects. The Apache 2.0 License, Mozilla Public License 2.0, Eclipse Public License, the newer GPL licenses, and both Microsoft licenses reflect this shift in language. Each license explicitly talks about patent licenses. Each license has language that covers patent litigation to varying degrees.&lt;/p&gt;

&lt;p&gt;I mention legal jurisdiction in the big levers category because some licenses explicitly mention it and this can be a real show stopper for some people. For that reason alone I treat it as a Big Lever. (The Mozilla Public License 2.0 specifically tries to deal with jurisdiction as one of changes from the original MPL, as that was often a criticism of the earlier license.)&lt;/p&gt;

&lt;p&gt;Other considerations in license choice include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Are there project specific affinities?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;History of the license and foundation/corporate/commercial involvement?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &amp;ldquo;language&amp;rdquo; projects (Perl, PHP, Python) each have their own licenses (Artistic License 2.0, PHP License 3.0, and Python License 2.0 respectively). If you are working on a project that closely ties to a specific open source programming language community then you should obviously consider that community’s license as the question of mixing modules and dependencies will be simplified with respect to open source licenses.&lt;/p&gt;

&lt;p&gt;As software IP law has evolved and the Internet has become an enormous space for people to collaborate on software development, commercial organizations became involved. We have seen the creation of open source software foundations with specific licenses associated with them. Corporate legal teams have become involved in authoring open source licenses, and the language and structure of these licenses (e.g. terminology and definitions) reflect this involvement. Lawyers without a lot of experience in open source licenses may feel more comfortable reviewing these newer licenses.&lt;/p&gt;

&lt;p&gt;So to recap, presuming that your primary motivation is to co-develop and collaborate on an open source project, in my way of looking at open source licenses your choices break down roughly as follows. (I&amp;rsquo;m keeping the discussion here to widely used licenses and/or licenses where large commercial organizations with conservative counsel or neutral non-profit open source foundations had a hand in their creation.)&lt;/p&gt;

&lt;p&gt;If you want to allow anyone to do anything at any time with the software, use the MIT or new (3-clause) BSD license, i.e. no copyleft and no discussion of patents. Both of these licenses came from the academic world, and both from a period of time where software patents were not a focus.&lt;/p&gt;

&lt;p&gt;If you want to allow anyone to do anything with the software (so no copyleft), but feel something needs to be said about patents and license termination in the face of litigation, and/or you want a license that corporate counsel is more comfortable reading then look at either the Apache 2.0 license or possibly the Microsoft Permissive License. These licenses were written to continue to encourage a completely open sharing environment but were written with a more corporate view (note the structure and language), and both begin to cover patents with varying (and subtly different) degrees of patent retaliation built into them.&lt;/p&gt;

&lt;p&gt;If you feel others should be able to build [possibly product] around your software, but want to ensure changes to the core software project itself remain open source (i.e. the changes must be published), you likely want to look to either the Eclipse Public License, the newer Mozilla Public License 2.0, or the Microsoft Reciprocal License. These are modern licenses developed from commercial/corporate perspectives supporting &amp;ldquo;weak&amp;rdquo; copyleft. [N.B. The EPL does name NY State as the jurisdiction.] Pay attention to patent statements in each.&lt;/p&gt;

&lt;p&gt;If you are a firm supporter of software freedom or want to ensure that if your software source is used anywhere that the resulting derivatives are maximally published as open source ensuring software freedom, then you should look to GPL2.0 or GPL3.0 depending upon your needs.&lt;/p&gt;

&lt;p&gt;There are a couple of interesting side ideas I’ve come across in the open source licensing space as different projects wrestled with how best to create the &amp;ldquo;right&amp;rdquo; licensing for their software.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Many companies are concerned about their patent portfolios when creating open source projects. Google took an interesting approach to the problem when they released the WebM project. They chose the New BSD license and then created a very specific &amp;ldquo;Additional IP Rights Grant&amp;rdquo; to cover the patent language they needed.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;It is the nature of IP law that the owner of the property can license it as many ways to as many people as they choose. This is why the Microsoft EULA for a personal copy of the Windows operating system is different from an Enterprise License Agreement and how MySQL AB developed a line of business around closed software licensing as well as their GPL-licensed project. In the early days (up through PHP3), the software from the PHP project was similarly &amp;ldquo;dual&amp;rdquo; licensed under both the GPL2.0 and an earlier PHP license to allow the software to be included in as many places as possible because the GPL was not directly compatible with the PHP license of the time.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I have deliberately not tried to create a table or decision tree for license choice here. I believe there are sufficient edges and nuances to license choice that it can never be properly &amp;ldquo;automated&amp;rdquo; with the licenses we have today that reflect their rich background of needs and history. There is always one more legal question of &amp;ldquo;what about the situation when&amp;hellip;?&amp;rdquo; Such questions will likely involve legal counsel and may be very jurisdiction sensitive.&lt;/p&gt;

&lt;p&gt;Likewise, open source software licenses don’t simply reflect a set of legal choices. In the early stage of an open source project when the author or authors are first publishing the software, the choice of license reflects as much of the social contract that is being made for the project as any legal requirements. It is the first governance document of the early possible community that comes into play long before formal governance, mission statements, and codes of conduct may be created around growing community.&lt;/p&gt;

&lt;p&gt;Full text of all the licenses can be found on the Open Source Initiative at: &lt;a href=&#34;http://opensource.org/licenses/alphabetical&#34;&gt;http://opensource.org/licenses/alphabetical&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Excellent information on how to consider various software licenses in combination with the GPL can be found here: &lt;a href=&#34;http://www.gnu.org/licenses/license-list.html#SoftwareLicenses&#34;&gt;http://www.gnu.org/licenses/license-list.html#SoftwareLicenses&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you need to get a lawyer up to speed, consider pointing them to: &lt;a href=&#34;http://www.ifosslr.org/ifosslr&#34;&gt;http://www.ifosslr.org/ifosslr&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Originally posted on the Outercurve Foundation Blog. Reposted with permission.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This blog was originally published by Stephen R. Walli at &lt;a href=&#34;https://opensource.com/law/13/1/which-open-source-software-license-should-i-use&#34;&gt;https://opensource.com/law/13/1/which-open-source-software-license-should-i-use&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;All content licensed under the &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/3.0/us/&#34;&gt;Creative Commons Attribution-Share Alike 3.0 United States&lt;/a&gt; License (CC BY-SA 3.0 US).&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Open Organizations</title>
      <link>http://lambdastack.io/blog/2017/02/22/open_org/</link>
      <pubDate>Wed, 22 Feb 2017 15:00:00 +0200</pubDate>
      
      <guid>http://lambdastack.io/blog/2017/02/22/open_org/</guid>
      <description>

&lt;h4 id=&#34;open-organizations&#34;&gt;Open Organizations&lt;/h4&gt;

&lt;p&gt;I have been asked recently a number of times about how best to bring teams together (not physically) and get buy-in on important projects especially when the org structure is more Matrix. Of course, there is no silver bullet to speak of in this case. Each organization has it&amp;rsquo;s own political structure that may have to be navigated which is so unfortunate because most people are not comfortable with change.&lt;/p&gt;

&lt;p&gt;Change should be &lt;strong&gt;embraced and enjoyed&lt;/strong&gt; (assuming the change is in the right direction). There are several things that I feel an organization should look strongly at, Amazon&amp;rsquo;s Leadership Principals and becoming an Open Organization.&lt;/p&gt;

&lt;p&gt;I follow &lt;a href=&#34;https://opensource.com&#34;&gt;https://opensource.com&lt;/a&gt; about Open Organizations. &lt;a href=&#34;https://opensource.com/open-organization/17/2/5-elements-teams-organized?sc_cid=7016000000122FhAAI&#34;&gt;Here is a good article this week (click here).&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rust</title>
      <link>http://lambdastack.io/blog/2017/02/20/rust/</link>
      <pubDate>Mon, 20 Feb 2017 13:00:20 +0200</pubDate>
      
      <guid>http://lambdastack.io/blog/2017/02/20/rust/</guid>
      <description>

&lt;h3 id=&#34;rust-programming&#34;&gt;&lt;code&gt;Rust&lt;/code&gt; Programming&lt;/h3&gt;

&lt;p&gt;A programming language from Heaven! Unlike the language of sorcerers, &lt;code&gt;Ruby&lt;/code&gt;, &lt;code&gt;Rust&lt;/code&gt; is a real language that gives you all of the speed and power benefits of &lt;code&gt;C/C++&lt;/code&gt;, functional model of some scripting languages and true safety that only Rust can provide.&lt;/p&gt;

&lt;h4 id=&#34;c-c-and-python&#34;&gt;C/C++ and Python&lt;/h4&gt;

&lt;p&gt;I cut my teeth on C and C++ many years ago. I actually won many awards for writing &lt;code&gt;Best C/C++ Middleware&lt;/code&gt; from Database Advisor Magazine (dating myself). I went on to love &lt;code&gt;Python&lt;/code&gt; and it soon became my &lt;code&gt;goto&lt;/code&gt; language. Python is a very good scripting language but it lacks true multi-threaded support (GIL) and strong types. I know, &lt;code&gt;CPython&lt;/code&gt; can give you good performance and a few other goodies but overall Python has its place as a good dynamic language.&lt;/p&gt;

&lt;h4 id=&#34;ruby&#34;&gt;Ruby&lt;/h4&gt;

&lt;p&gt;A number of years ago I remember having a debate with a member of my team that I managed about Ruby. He swore up and down how awesome it was and that I would have to try it to really believe him. Of course, I resisted even looking in the direction of Ruby until I was forced to by my employer due to Chef and Puppet. Since then I have written a number of Ruby custom modules for Chef and yes it&amp;rsquo;s simple but it has really odd syntax that likens itself to ancient symbols you see in horror movies - a sorcery language.&lt;/p&gt;

&lt;h4 id=&#34;java&#34;&gt;Java&lt;/h4&gt;

&lt;p&gt;Another language that I have had to endure in my career is Java. I remember when Java was introduced (I keep dating myself). It promised so much but it&amp;rsquo;s initial performance was horrible. Since then, of course, the performance has dramatically improved but the verbosity of the code has not gotten any better. Today, it&amp;rsquo;s still used in a number of Enterprises but in a more monolithic nature - old school tech. When I see tech that is Java based, I can&amp;rsquo;t help to immediately think &lt;code&gt;outdated&lt;/code&gt;. I could go on and on about Java but you get the point.&lt;/p&gt;

&lt;h4 id=&#34;go&#34;&gt;GO&lt;/h4&gt;

&lt;p&gt;GO is actually a very good systems language. I like it a lot. It was built from ground up to support modern architectures but it too has issues. The compiled code is sort of bloated, it&amp;rsquo;s development dependency management was not really thought out ahead of time (folks have started a &lt;code&gt;pseudo best practices&lt;/code&gt; which has helped) and it&amp;rsquo;s super easy to hurt yourself at runtime like in C/C++ - just look at Docker. It will compile easily but &lt;code&gt;easy&lt;/code&gt; compilations can come at a big cost at runtime.&lt;/p&gt;

&lt;h4 id=&#34;rust&#34;&gt;Rust&lt;/h4&gt;

&lt;p&gt;Again, I&amp;rsquo;m a C/C++ guy at heart. I want everything to run at the speed of light, have no runtime dependencies and have a very small memory footprint. This of course causes all of the languages mentioned thus far to strike out except for C/C++ and GO.&lt;/p&gt;

&lt;p&gt;When I first saw &lt;code&gt;Rust&lt;/code&gt; I thought, &amp;ldquo;great, another language.&amp;rdquo; I was working with GO and loved it&amp;rsquo;s simple model but found it&amp;rsquo;s development dependency model to be a pain. I wasn&amp;rsquo;t looking at learning a new language but I took a look while sitting in the Orlando airport on my way back to NYC (I know; I spend my time on odd things). For the first hour I was amazed at how simple it was to get Rust installed and how organized the development dependencies were with &lt;code&gt;Cargo&lt;/code&gt; (Rust&amp;rsquo;s package management system). I was able to build a small app (a little more than Hello World!) before boarding. While on the plane I read more about Rust and thus began my journey.&lt;/p&gt;

&lt;p&gt;It wasn&amp;rsquo;t long before I realized that Rust too used some very odd syntax (lifetimes) and I lost even more hair struggling over the &lt;code&gt;borrower checker&lt;/code&gt;. For Rust to guarantee runtime safety, it must implement tight controls up front during the compilation period. This is completely different than any other programming model so it can take a while to get your head around it. However, once you do, there is no going back. You begin to really appreciate the lifetime management system and how to code in a model that guarantees thread safety etc.&lt;/p&gt;

&lt;p&gt;I can happily say I am now &lt;code&gt;Team Rust&lt;/code&gt; and actually love coding in Rust. I still love Python and do some low-level things in C where needed but my heart is with Rust. Oh, I still have to adorn my black robe in secret and chant &lt;code&gt;Ruby&lt;/code&gt; while working on my employer&amp;rsquo;s Chef code - necessary evil I suppose!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ceph and SMR Drives - NO</title>
      <link>http://lambdastack.io/blog/2017/02/13/smr/</link>
      <pubDate>Mon, 13 Feb 2017 11:27:27 -0400</pubDate>
      
      <guid>http://lambdastack.io/blog/2017/02/13/smr/</guid>
      <description>

&lt;h4 id=&#34;don-t-use-ceph-with-smr-drives&#34;&gt;Don&amp;rsquo;t use Ceph with SMR Drives!&lt;/h4&gt;

&lt;p&gt;A while back at Ceph Day in NYC I saw a representative from a drive manufacturer talk about SMR drives. SMR stands for &lt;a href=&#34;https://en.wikipedia.org/wiki/Shingled_magnetic_recording&#34;&gt;&lt;code&gt;Shingled Magnetic Recording&lt;/code&gt;&lt;/a&gt; and the analogy given was &amp;lsquo;think about the shingles on a house&amp;rsquo;. It sounded very interesting but they were not on the market at the time.&lt;/p&gt;

&lt;p&gt;A very active community member, Wido den Hollander, posted his findings &lt;a href=&#34;https://blog.widodh.nl/2017/02/do-not-use-smr-disks-with-ceph/&#34;&gt;here&lt;/a&gt;. The net result was &lt;code&gt;DO NOT USE SMR DRIVES!&lt;/code&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hugo vs WordPress</title>
      <link>http://lambdastack.io/blog/2017/02/01/hugo/</link>
      <pubDate>Wed, 01 Feb 2017 13:00:20 +0200</pubDate>
      
      <guid>http://lambdastack.io/blog/2017/02/01/hugo/</guid>
      <description>

&lt;h3 id=&#34;hugo-vs-wordpress&#34;&gt;&lt;code&gt;Hugo&lt;/code&gt; vs &lt;code&gt;WordPress&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;We all know that &lt;code&gt;WordPress&lt;/code&gt; is a Content Management System (CMS). For years, people have been using WordPress to help them manage their content and for the most part it works - sort of. WordPress is a very old tech code base. It&amp;rsquo;s written in PHP (who uses that anymore?) using Apache/NGINX and it uses MySQL as it SQL backend. None of those are bad on their own (except PHP) but the way that WordPress is organized and Architected makes it very prone to scalability issues and it&amp;rsquo;s an anti-pattern of &lt;code&gt;Microservices&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This site was originally a WordPress site and used a different domain name. I even tried Wordpress.com but you&amp;rsquo;re not allowed to upload your own custom templates which seems odd to me. I even tried other blogging sites like &lt;code&gt;Medium&lt;/code&gt; and &lt;code&gt;Blogger&lt;/code&gt; but being a developer and architect, I wanted more freedom. Like all good developers, I went back to my original idea. I looked at hosting on BlueHost and others but I began to have a reaction when I had to pay a lot for hosting - no tech is easier to architect and manage than web servers.&lt;/p&gt;

&lt;p&gt;So, I had the idea that I would build-out an AWS EC2 environment and use Elastic Load Balancers to front the EC2 instances. I took the generic CloudFormation template and modified it to fit my needs. When executed, it built the EC2 instances, setup the ELB, setup RDS and had my hosting environment setup in no time using my custom WordPress template. BTW, I was using Amazon Linux AMIs. The code base is located &lt;a href=&#34;https://github.com/lambdastackio/wordpress&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For some reason, I had in my mind that my costs would be almost nothing - my traffic was good but not excessive. My first AWS bill was over &lt;strong&gt;$70&lt;/strong&gt;. When I drilled down into the invoice I noticed my instance types were too high, my RDS was too much etc. I changed the types down to micro level on everything I could. This lowered the next bill down to a little more than &lt;strong&gt;$50&lt;/strong&gt;. I also had an instance go south on me and I had to manage the site which I did not want to do. I started thinking that I should have just paid a hosting company to deal with the goofy issues associated with WordPress. I was about to move to a hosting company when I ran across &lt;a href=&#34;https://gohugo.io/&#34;&gt;&lt;code&gt;Hugo&lt;/code&gt;&lt;/a&gt;, a static website generator built in GO.&lt;/p&gt;

&lt;p&gt;I installed &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; and played around with it and thought it was super simple to use but it was a static site generator and not a CMS. What if I wanted to use my iPad or iPhone to write posts while traveling? Was that feature worth $50+ a month? The answer was obvious - nope!&lt;/p&gt;

&lt;p&gt;It took me a few days to figure out the templates and how to override the parts I wanted to customized. Once I saw how fast and simple it was to customized I began to really enjoy it. After a week or so I actually enjoyed working with it (I never said that about WordPress).&lt;/p&gt;

&lt;p&gt;Today this site uses Hugo to generate the site based on &lt;code&gt;Markdown&lt;/code&gt; and I simply use a custom domain &lt;code&gt;lambdastack.io&lt;/code&gt; on &lt;code&gt;Github&lt;/code&gt; and post the code to the &lt;code&gt;docs&lt;/code&gt; folder. The code for the site can be found &lt;a href=&#34;https://github.com/lambdastackio/website&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Hugo and Github hosting work very well and everything is version controlled. It&amp;rsquo;s so simple to change and add things. The only odd things I have seen has been &lt;code&gt;Github&lt;/code&gt; related. If you have a good bit of traffic then push to AWS S3 and use Cloud Front. BTW, I no longer use the WordPress HA platform I built on AWS - &lt;strong&gt;Github is free!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Update: We use Github Enterprise at work but it does not allow for custom domains so I had to add a deployment pipeline hooked to github push which then pushes the docs site to all of my HA Web Servers&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TCP and Load Balancers</title>
      <link>http://lambdastack.io/blog/2017/01/20/tcp_and_load_balancers/</link>
      <pubDate>Fri, 20 Jan 2017 11:54:20 +0200</pubDate>
      
      <guid>http://lambdastack.io/blog/2017/01/20/tcp_and_load_balancers/</guid>
      <description>

&lt;h4 id=&#34;why-do-i-get-a-tcp-rst-return-when-i-try-to-put-or-get-s3-objects&#34;&gt;Why do I get a &lt;code&gt;TCP RST&lt;/code&gt; return when I try to PUT or GET S3 objects?&lt;/h4&gt;

&lt;p&gt;I have a colleague that has made the following statement:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;The data is sacred but, the requests are not!&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This holds very true when dealing with HTTP calls such as S3 GETs and PUTs.&lt;/p&gt;

&lt;p&gt;Recently, we noticed that a client was doing a massive amounts of PUTs and then issuing corresponding GETs on the same S3 objects. In our case, our S3 is from Ceph&amp;rsquo;s RGW S3 and we have a number of load balancers in front of all of the RGW servers. The client had &amp;ldquo;rolled&amp;rdquo; their own S3 Python SDK instead of using AWS&amp;rsquo; official Python SDK. In doing so, they had not factored in best practices of exponential backoffs (retries).&lt;/p&gt;

&lt;p&gt;When running similar tests against the RGW cluster directly (no load balancers), we were never able to replicate which pointed to the network or the load balancers or both. We had tested this on both commercial and open source load balancers.&lt;/p&gt;

&lt;p&gt;TCP RST return values are usually associated with some sort of &amp;ldquo;man-in-the-middle&amp;rdquo; process such as load balancers, proxies or traffic sniffers. In our case, load balancers. By default, we disabled &lt;code&gt;no linger&lt;/code&gt; features which in theory would imply that the load balancers were not holding on to connections from the clients. We also had very low timeouts set as default.&lt;/p&gt;

&lt;p&gt;After spending days testing and letting our tests run for 24 hour periods we found that on the open source version if you specify &lt;code&gt;no linger&lt;/code&gt; explicitly the issue goes away or dramatically reduces to just noise. For the commercial load balancers we upped the timeouts to 40s which addressed the issue.&lt;/p&gt;

&lt;p&gt;In our case, the client did not want to enable retries in their code due to their own reasons. However, for those clients that had used best practices of exponential backoffs, they never saw an issue to begin with. By combining reasonable timeouts and lingering on your load balancers along with educating clients to code in retries, managing your S3 on-premise cluster becomes a lot easier.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Klaus - Hybrid WebStack</title>
      <link>http://lambdastack.io/blog/2017/01/15/klaus/</link>
      <pubDate>Sun, 15 Jan 2017 15:00:00 +0200</pubDate>
      
      <guid>http://lambdastack.io/blog/2017/01/15/klaus/</guid>
      <description>&lt;p&gt;There are very good Web Servers on the market, Apache and NGINX to name a few. However, to interface your backend code you need to use Apache modules or WSGI/FastCGI with NGINX (depending on your language of choice). To actually use a fully integrated environment you need to use something like Django or Tornado for Python. For GO there is a small built-in web server that allows you to build up a more robust environment around it. But for Rust, not so much - until now.&lt;/p&gt;

&lt;p&gt;My original goto languages of choice were C/C++ and then some time ago I switched to Python as my first choice. But, after working with Rust this past year, there is no way I would go back. Rust gives me an environment with no runtime dependencies with the speed of optimized C/C++ code but with safety guarantees. This makes deploying code written in Rust as simple as moving an executable around. Contrast that with Python, Ruby or Java where you can easily spend more time making sure the dependencies are in place than actually writing the code in some cases.&lt;/p&gt;

&lt;p&gt;As wonderful as Rust is there are a few missing pieces, a built-in default web server code to build on. However, there are several great projects that allow for powerful async I/O in a multi-threaded model that have guaranteed safety. One such project is called Klaus-rs. Klaus has not reached it&amp;rsquo;s 1.0 status but is very close. It&amp;rsquo;s what I call a full &amp;ldquo;hybrid model&amp;rdquo; which means it can run as a stand-alone Web Server that serves static pages as well as single page Javascript apps like React or Angular without any funky configuration changes. It just works out of the box so to speak. Klaus also works as an Agent model where it can reside in a background process to handle requests from other agents and initiate requests instead of simply responding to requests. It also has RESTful features built-in so setting up APIs are very simple and it will soon support built-in rate limiting via it&amp;rsquo;s built-in support for Redis.&lt;/p&gt;

&lt;p&gt;One of the greatest and simplest features is the built-in support for AWS S3. This means that it can support making S3 calls using your own AWS credentials. You don&amp;rsquo;t have to create a funky piece of code and bolt it on to handle automatic uploads to S3 for example. Since it&amp;rsquo;s built in Rust and most of the code resides in a library, you can easily extend it to support your environment. The memory footprint is very small so running in a Docker container is also an ideal solution.&lt;/p&gt;

&lt;p&gt;Why call it Klaus? The name is based off of a fictional character from the TV series called The Originals. In the series, Klaus is one of the first Vampires but what makes him so lethal is the fact that he is also part Werewolf making him a true hybrid that can survive anything. So, Klaus-rs can survive any distributed environment including Silver and Daylight!&lt;/p&gt;

&lt;p&gt;To get started, simply fork the github project at &lt;a href=&#34;https://github.com/klaus-rs/klaus&#34;&gt;https://github.com/klaus-rs/klaus&lt;/a&gt; and start building. This of course assumes you have Rust installed if you plan on building it from source. To install Rust go to &lt;a href=&#34;https://rustup.rs&#34;&gt;https://rustup.rs&lt;/a&gt; and follow the instructions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Continuous Delivery - Principles</title>
      <link>http://lambdastack.io/blog/2016/12/30/cicd-principles/</link>
      <pubDate>Fri, 30 Dec 2016 15:00:00 +0200</pubDate>
      
      <guid>http://lambdastack.io/blog/2016/12/30/cicd-principles/</guid>
      <description>

&lt;h3 id=&#34;principles&#34;&gt;Principles&lt;/h3&gt;

&lt;p&gt;There are five principles at the heart of continuous delivery:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Build quality in&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Work in small batches&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Computers perform repetitive tasks, people solve problems&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Relentlessly pursue continuous improvement&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Everyone is responsible&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It’s easy to get bogged down in the details of implementing continuous delivery—tools, architecture, practices, politics—if you find yourself lost, try revisiting these principles and you may find it helps you refocus on what’s important.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Build Quality In&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;W. Edwards Deming, a key figure in the history of the Lean movement, offered 14 key principles for management. Principle three states, “Cease dependence on inspection to achieve quality. Eliminate the need for inspection on a mass basis by building quality into the product in the first place.”&lt;/p&gt;

&lt;p&gt;It’s much cheaper to fix problems and defects if we find them immediately—ideally before they are ever checked into version control, by running automated tests locally. Finding defects downstream through inspection (such as manual testing) is time-consuming, requiring significant triage. Then we must fix the defect, trying to recall what we were thinking when we introduced the problem days or perhaps even weeks ago.&lt;/p&gt;

&lt;p&gt;Creating and evolving feedback loops to detect problems as early as possible is essential and never-ending work in continuous delivery. If we find a problem in our exploratory testing, we must not only fix it, but then ask: How could we have caught the problem with an automated acceptance test? When an acceptance test fails, we should ask: Could we have written a unit test to catch this problem?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Work in Small Batches&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In traditional phased approaches to software development, handoffs from dev to test or test to IT operations consist of whole releases: months worth of work by teams consisting of tens or hundreds of people.&lt;/p&gt;

&lt;p&gt;In continuous delivery, we take the opposite approach, and try and get every change in version control as far towards release as we can, getting comprehensive feedback as rapidly as possible.&lt;/p&gt;

&lt;p&gt;Working in small batches has many benefits. It reduces the time it takes to get feedback on our work, makes it easier to triage and remediate problems, increases efficiency and motivation, and prevents us from succumbing to the sunk cost fallacy.&lt;/p&gt;

&lt;p&gt;The reason we work in large batches is because of the large fixed cost of handing off changes. A key goal of continuous delivery is to change the economics of the software delivery process to make it economically viable to work in small batches so we can obtain the many benefits of this approach.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Computers Perform Repetitive Tasks, People Solve Problems&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;One of the earliest philosophical ideas of the Toyota tradition is jidoka, sometimes translated as “automation with a human touch.” The goal is for computers to perform simple, repetitive tasks, such as regression testing, so that humans can focus on problem-solving. Thus computers and people complement each other.&lt;/p&gt;

&lt;p&gt;Many people worry that automation will put them out of a job. This is not the goal. There will never be a shortage of work in a successful company. Rather, people are freed up from mindless drudge-work to focus on higher value activities. This also has the benefit of improving quality, since humans are at their most error-prone when performing mindless tasks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Relentlessly Pursue Continuous Improvement&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Continuous improvement, or kaizen in Japanese, is another key idea from the Lean movement. Taiichi Ohno, a key figure in the history of the Toyota company, once said,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Kaizen opportunities are infinite. Don’t think you have made things better than before and be at ease… This would be like the student who becomes proud because they bested their master two times out of three in fencing. Once you pick up the sprouts of kaizen ideas, it is important to have the attitude in our daily work that just underneath one kaizen idea is yet another one.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Don’t treat transformation as a project to be embarked on and then completed so we can return to business as usual. The best organizations are those where everybody treats improvement work as an essential part of their daily work, and where nobody is satisfied with the status quo.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Everyone is Responsible&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In high performing organizations, nothing is “somebody else’s problem.” Developers are responsible for the quality and stability of the software they build. Operations teams are responsible for helping developers build quality in. Everyone works together to achieve the organizational level goals, rather than optimizing for what’s best for their team or department.&lt;/p&gt;

&lt;p&gt;When people make local optimizations that reduce the overall performance of the organization, it’s often due to systemic problems such as poor management systems such as annual budgeting cycles, or incentives that reward the wrong behaviors. A classic example is rewarding developers for increasing their velocity or writing more code, and rewarding testers based on the number of bugs they find.&lt;/p&gt;

&lt;p&gt;Most people want to do the right thing, but they will adapt their behavior based on how they are rewarded. Therefore, it is very important to create fast feedback loops from the things that really matter: how customers react to what we build for them, and the impact on our organization.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This blog was originally published by Jez Humble at &lt;a href=&#34;https://continuousdelivery.com&#34;&gt;https://continuousdelivery.com&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;All content licensed under the &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/3.0/us/&#34;&gt;Creative Commons Attribution-Share Alike 3.0 United States&lt;/a&gt; License (CC BY-SA 3.0 US).&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Continuous Testing</title>
      <link>http://lambdastack.io/blog/2016/12/15/cdtesting/</link>
      <pubDate>Thu, 15 Dec 2016 15:00:00 +0200</pubDate>
      
      <guid>http://lambdastack.io/blog/2016/12/15/cdtesting/</guid>
      <description>

&lt;h3 id=&#34;continuous-testing&#34;&gt;Continuous Testing&lt;/h3&gt;

&lt;p&gt;The key to building quality into our software is making sure we can get fast feedback on the impact of changes. Traditionally, extensive use was made of manual inspection of code changes and manual testing (testers following documentation describing the steps required to test the various functions of the system) in order to demonstrate the correctness of the system. This type of testing was normally done in a phase following “dev complete”. However this strategy have several drawbacks:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Manual regression testing takes a long time and is relatively expensive to perform, creating a bottleneck that prevents us releasing software more frequently, and getting feedback to developers weeks (and sometimes months) after they wrote the code being tested.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Manual tests and inspections are not very reliable, since people are notoriously poor at performing repetitive tasks such as regression testing manually, and it is extremely hard to predict the impact of a set of changes on a complex software system through inspection.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;When systems are evolving over time, as is the case in modern software products and services, we have to spend considerable effort updating test documentation to keep it up-to-date.
In order to build quality in to software, we need to adopt a different approach. Our goal is to run many different types of tests—both manual and automated—continually throughout the delivery process. The types of tests we want to run are nicely laid out the quadrant diagram created by Brian Marick, below:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://lambdastack.io/img/cicd/test-quadrant.png&#34; style=&#34;max-width: 100%&#34;&gt;&lt;/p&gt;

&lt;p&gt;Once we have continuous integration and test automation in place, we create a deployment pipeline (the key pattern in continuous delivery). In the deployment pipeline pattern, every change runs a build that a) creates packages that can be deployed to any environment and b) runs unit tests (and possibly other tasks such as static analysis), giving feedback to developers in the space of a few minutes. Packages that pass this set of tests have more comprehensive automated acceptance tests run against them. Once we have packages that pass all the automated tests, they are available for self-service deplyment to other environments for activities such as exploratory testing, usability testing, and ultimately release. Complex products and services may have sophisticated deployment pipelines; a simple, linear pipeline is shown below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://lambdastack.io/img/cicd/pipeline-sequence.png&#34; style=&#34;max-width: 100%&#34;&gt;&lt;/p&gt;

&lt;p&gt;In the deployment pipeline, every change is effectively a release candidate. The job of the deployment pipeline is to catch known issues. If we can’t detect any known problems, we should feel totally comfortable releasing any packages that have gone through it. If we aren’t, or if we discover defects later, it means we need to improve our pipeline, perhaps adding or updating some tests.&lt;/p&gt;

&lt;p&gt;Our goal should be to find problems as soon as possible, and make the lead time from check-in to release as short as possible. Thus we want to parallelize the activities in the deployment pipeline, not have many stages executing in series. There is also a feedback process: if we discover bugs in exploratory testing, we should be looking to improve our automated tests. If we discover a defect in the acceptance tests, we should be looking to improve our unit tests (most of our defects should be discovered through unit testing).&lt;/p&gt;

&lt;p&gt;Get started by building a skeleton deployment pipeline—create a single unit test, a single acceptance test, an automated deployment script that stands up an exploratory testing envrionment, and thread them together. Then increase test coverage and extend your deployment pipeline as your product or service evolves.&lt;/p&gt;

&lt;h4 id=&#34;resources&#34;&gt;Resources&lt;/h4&gt;

&lt;p&gt;A &lt;a href=&#34;https://youtu.be/X9ap-zH0Gkc&#34;&gt;1h video&lt;/a&gt; in which Badri Janakiraman and I discuss how to create maintainable suites of automated acceptance test&lt;/p&gt;

&lt;p&gt;Lisa Crispin and Janet Gregory have two great books on agile testing: Agile Testing and More Agile Testing&lt;/p&gt;

&lt;p&gt;Elisabeth Hendrickson has written an excellent book on exploratory testing, Explore It!. I recorded an interview with her where we discuss the role of testers, acceptance test driven development, and the impact of continuous delivery on testing. Watch her awesome 30m talk On the Care and Feeding of Feedback Cycles.&lt;/p&gt;

&lt;p&gt;Gojko Adzic’s Specification By Example has a series of interviews with successful teams worldwide and is a good distillation of effective patterns for specifying requirements and tests.&lt;/p&gt;

&lt;p&gt;Think that “a few minutes” is optimistic for running automated tests? Read Dan Bodart’s blog post &lt;a href=&#34;http://dan.bodar.com/2012/02/28/crazy-fast-build-times-or-when-10-seconds-starts-to-make-you-nervous/&#34;&gt;Crazy fast build times&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://martinfowler.com/bliki/TestPyramid.html&#34;&gt;Martin Fowler discusses the Test Pyramid and its evil twin, the ice cream cone on his blog.&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;faq&#34;&gt;FAQ&lt;/h4&gt;

&lt;p&gt;Does continuous delivery mean firing all our testers?&lt;/p&gt;

&lt;p&gt;No. Testers have a unique perspective on the system—they understand how users interact with it. I recommend having testers pair alongside developers (in person) to help them create and evolve the suites of automated tests. This way, developers get to understand the testers’ perspective, and testers can start to learn test automation. Testers should also be performing exploratory testing continuously as part of their work. Certainly, testers will have to learn new skills—but that is true of anybody working in our industry.&lt;/p&gt;

&lt;p&gt;Should we be automating all of our tests?&lt;/p&gt;

&lt;p&gt;No. As shown in the quadrant diagram, there are still important manual activities such as exploratory testing and usability testing (although automation can help with these activities, it can’t replace people). We should be aiming to bring all test activities, including security testing, into the development process and performing them continually from the beginning of the software delivery lifecycle for every product and service we build.&lt;/p&gt;

&lt;p&gt;Should I stop and automate all of my manual tests right now?&lt;/p&gt;

&lt;p&gt;No. Start by writing a couple of automated tests—the ones that validate the most important functionality in the system. Get those running on every commit. Then the rule is to add new tests to cover new functionality that is added, and functionality that is being changed. Over time, you will evolve a comprehensive suite of automated tests. In general, it’s better to have 20 tests that run quickly and are trusted by the team than 2,000 tests that are flaky and constantly failing and which are ignored by the team.&lt;/p&gt;

&lt;p&gt;Who is responsible for the automated tests?&lt;/p&gt;

&lt;p&gt;The whole team. In particular, developers should be involved in creating and maintaining the automated tests, and should stop what they are doing and fix them whenever there is a failure. This is essential because it teaches developers how to write testable software. When automated tests are created and maintained by a different group from the developers, there is no force acting on the developers to help them write software that is easy to test. Retrofitting automated tests onto such systems is painful and expensive, and poorly designed software that is hard to test is a major factor contributing to automated test suites that are expensive to maintain.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This blog was originally published by Jez Humble at &lt;a href=&#34;https://continuousdelivery.com&#34;&gt;https://continuousdelivery.com&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;All content licensed under the &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/3.0/us/&#34;&gt;Creative Commons Attribution-Share Alike 3.0 United States&lt;/a&gt; License (CC BY-SA 3.0 US).&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>